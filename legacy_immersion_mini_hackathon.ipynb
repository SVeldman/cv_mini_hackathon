{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the Legacy Immersion Weekend Mini-Hackathon and Scavenger Hunt!\n",
        "\n",
        "This notebook will walk you through a simple computer vision challenge lovingly and painstakingly designed by your dedicated event organizers.\n",
        "\n",
        "The dataset consists of architectural images from around Chicago. When you download the dataset it will already be split into training and validation sets, and each dataset's directory will be further broken down by image label (\"1\" representing the positive class and \"0\" representing the negative class).\n",
        "\n",
        "Your task is to build a computer vision model that can distinguish between these two classes, and use it to extract the images containing your scavenger hunt clues from the test dataset."
      ],
      "metadata": {
        "id": "uPYUUatndaHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup:\n",
        "Run these first two cells to download and unzip the dataset, and to pre-load some libraries and APIs that will be useful for this challenge.\n",
        "\n",
        "Note: Before you begin, make sure that your colab session is connected to a GPU-enabled runtime (ideally an A100 if available). This challenge will take more time than we have available if you run it on a CPU runtime."
      ],
      "metadata": {
        "id": "Wrmkpa79V7QP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7blClgYDgnxH"
      },
      "outputs": [],
      "source": [
        "#!pip install requests\n",
        "import requests\n",
        "import shutil\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Dense, Dropout, Flatten, BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, GlobalAveragePooling2D\n",
        "\n",
        "from tqdm.keras import TqdmCallback\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint"
      ]
    },
    {
      "source": [
        "# Download the dataset file from huggingface and unzip:\n",
        "dataset_id = \"SVeldman/cv_challenge_9_21_24\"\n",
        "filename = \"cv_challenge_dataset.zip\"\n",
        "\n",
        "url = f\"https://huggingface.co/datasets/{dataset_id}/resolve/main/{filename}\"\n",
        "\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Raise an exception for non-200 status codes\n",
        "\n",
        "with open(filename, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "!unzip cv_challenge_dataset.zip\n",
        "\n",
        "source_path = '/content/content/dataset'\n",
        "destination_path = '/content/dataset'\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "  shutil.move(source_path, destination_path)\n",
        "\n",
        "shutil.rmtree('/content/content')"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "fkKAHA1OojMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instantiate Dataset Objects:\n",
        "\n",
        "Use the Keras API to create datasets \"train\" and \"val\" from the two folders inside the dataset directory.\n",
        "\n",
        "(hint: https://keras.io/api/data_loading/image/)"
      ],
      "metadata": {
        "id": "mlPZvitHWfxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define training dataset:\n",
        "train = # insert your code here\n",
        "\n",
        "# define validation dataset:\n",
        "val = # insert your code here"
      ],
      "metadata": {
        "id": "XItnksvoTsHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load a Pretrained Model:\n",
        "Use the Keras API to load a pretrained image classification model from Keras Applications (https://keras.io/api/applications/).\n",
        "\n",
        "Do not include the top layer of the base model, and make sure the base model is initially set to not be trainable (\"model.trainable = False\"). After that, you may unfreeze as many layers of the base model as you would like.\n",
        "\n",
        "(hint: click on the link for the model you want to use for more information on the arguments available when loading that model.)"
      ],
      "metadata": {
        "id": "cJNDRm_ZXcBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = # insert your code here\n",
        "base_model.trainable = False\n",
        "\n",
        "# unfreeze layers if desired:\n",
        "# insert your code here"
      ],
      "metadata": {
        "id": "4FD7nKUmrqyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add Additional Layers and Compile:\n",
        "\n",
        "At a minimum, you will need to add an output layer to your base model (this should be a dense layer with two neurons and a sigmoid activation function). You may choose to add additional layers between the base model and the output layer if you would like.\n",
        "\n",
        "Once you have defined your model, compile it.\n",
        "\n",
        "(https://keras.io/api/models/model_training_apis/#compile-method)"
      ],
      "metadata": {
        "id": "A74Yvcq_Z1DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add additional layers to base model:\n",
        "transfer_model = Sequential([\n",
        "    base_model,\n",
        "    # insert additional code here if desired,\n",
        "    Dense(2, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model:\n",
        "transfer_model.compile(# insert your code here)"
      ],
      "metadata": {
        "id": "eccdm_cXrzOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train your model using the train and validation datasets\n",
        "\n",
        "A validation accuracy of 90% should get you *most* of the clues, but time will be added to your team's scavenger hunt time for every clue your model fails to predict (or extra clue it predicts). Can you beat Steve's validation accuracy of 96.32%?\n",
        "\n",
        "(https://keras.io/api/models/model_training_apis/#fit-method)"
      ],
      "metadata": {
        "id": "Jfuq4_XwZ38t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train your model:\n",
        "transfer_model.fit(# insert your code here)"
      ],
      "metadata": {
        "id": "YZAyiopztUYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unlock the Scavenger Hunt Clues!\n",
        "Use the code below to download the test dataset. Run inference using your best model, and then use the final code cell to print the images that your model believes are the scavenger hunt clues."
      ],
      "metadata": {
        "id": "2_-4oBbRcMHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset file from huggingface and unzip:\n",
        "dataset_id = \"SVeldman/cv_challenge_9_21_24\"\n",
        "filename = \"test_dataset.zip\"\n",
        "\n",
        "url = f\"https://huggingface.co/datasets/{dataset_id}/resolve/main/{filename}\"\n",
        "\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()  # Raise an exception for non-200 status codes\n",
        "\n",
        "with open(filename, \"wb\") as f:\n",
        "    f.write(response.content)\n",
        "\n",
        "!unzip test_dataset.zip\n",
        "\n",
        "source_path = '/content/content/test_dataset'\n",
        "destination_path = '/content/test_dataset'\n",
        "\n",
        "if os.path.exists(source_path):\n",
        "  shutil.move(source_path, destination_path)\n",
        "\n",
        "shutil.rmtree('/content/content')"
      ],
      "metadata": {
        "id": "kxliREIPdXUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = keras.utils.image_dataset_from_directory(\n",
        "    \"/content/test\",\n",
        "    labels=None,\n",
        "    label_mode=None,\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=1,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=False,\n",
        "    seed=47,\n",
        "    interpolation=\"bilinear\",\n",
        "    #follow_links=False,\n",
        "    pad_to_aspect_ratio=True\n",
        ")"
      ],
      "metadata": {
        "id": "SxGSxl1ewNfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Designate your model as \"my_model\":\n",
        "my_model = transfer_model\n",
        "my_model.load_weights(\"tr_model_20_epochs.keras\")"
      ],
      "metadata": {
        "id": "it9NlLwtsohc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Predict on test dataset:\n",
        "predictions = my_model.predict(test)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the file paths from the dataset (remove decode())\n",
        "image_filenames = [element for element in test.file_paths]  # Remove decode()\n",
        "\n",
        "# Iterate through filenames and the dataset\n",
        "for i, (image, filename) in enumerate(zip(test.as_numpy_iterator(), image_filenames)):\n",
        "    if predicted_classes[i] == 1:\n",
        "        # Squeeze the image to remove the batch dimension\n",
        "        image = image.squeeze(0)\n",
        "        #loc_words = filename.split('/')[-1].split('.')[0].split('_')\n",
        "        loc_name = ' '.join(word.capitalize() for word in filename.split('/')[-1].split('.')[0].split('_'))\n",
        "\n",
        "        plt.imshow(image.astype(\"uint8\"))\n",
        "        plt.title(f\"Location: {loc_name}\")  # Use the filename for the title\n",
        "        plt.show()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "iu0qCF2z__CL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}